{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add new content to the manual_plus document and create an index for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from openai import OpenAI\n",
    "from regulations_rag.file_tools import load_parquet_data, save_parquet_data\n",
    "\n",
    "import data_tools.index_tools\n",
    "importlib.reload(data_tools.index_tools)\n",
    "from data_tools.index_tools import update_text_in_index, add_to_index, remove_from_index\n",
    "\n",
    "from cemad_rag.cemad_reference_checker import CEMADReferenceChecker\n",
    "cemad_reference_checker = CEMADReferenceChecker()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "secret_name = \"OPENAI_API_KEY_CEMAD\"\n",
    "openai_api_key = os.getenv(secret_name)\n",
    "openai_client = OpenAI(api_key=openai_api_key,)\n",
    "decryption_key = os.getenv('DECRYPTION_KEY_CEMAD')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_document_csv = \"./inputs/documents/ad_manual_plus.csv\"\n",
    "existing_df = pd.read_csv(existing_document_csv, encoding = 'utf-8', sep = \"|\", na_values=\"\",\n",
    "    keep_default_na=False)\n",
    "existing_df = existing_df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text to add should be in the same format as the rest of the manual so tools can be reused to process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Z.1 References (#Heading)\n",
    "    (C) Crypto Assets (#Heading)\n",
    "        (i) According to the Reserve Bank's official [FAQ page](https://www.resbank.co.za/en/home/what-we-do/financial-surveillance/FinSurvFAQ) \"The SARB does not currently oversee, supervise or regulate crypto assets, which were previously referred to as virtual currencies, but is continuing to monitor this evolving area. The SARBâ€™s position on crypto assets remains as set out in the [2014 Position Paper on Virtual Currencies](https://www.resbank.co.za/content/dam/sarb/what-we-do/financial-surveillance/general-public/Virtual%20Currencies%20Position%20Paper%20%20Final_02of2014.pdf)\"\n",
    "        More recently, the Crypto Assets Regulatory (CAR) Working Group (WG) published a [position paper](https://www.treasury.gov.za/comm_media/press/2021/IFWG_CAR%20WG_Position%20paper%20on%20crypto%20assets_Final.pdf) on Crypto Assets where they set out 25 recommendations for a revised South African policy, legal and regulatory position on crypto assets and related activities. This is intended to provide a roadmap to putting in place a framework for regulating crypto asset service providers in South Africa.\n",
    "        When these recommendations make it into regulations they will be included in this document. Until then please refer to the links to see the official position and where we may be heading. \n",
    "\"\"\"\n",
    "# sectinos_referenced is a column that is used when CEMAD is updated to ensure these additions can be updated to keep \n",
    "# up with changes in the manual\n",
    "# sections_referenced should be in the format of a dictionary {\"Z.1(A)(i)(c)\":\"B.4(B)(i), B.4(B)(ii), B.4(B)(iv)(a)\"}\n",
    "# where the key needs to exist in the text above\n",
    "sections_referenced = {}\n",
    "\n",
    "index_for_new_text = [\n",
    "    [\"Z.1(C)(i)\", \"What do the regulations say about Crypto?\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_tools.file_tools import process_regulations\n",
    "# Ensure the directory exists\n",
    "tmp_folder = './tmp'\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "file_name = tmp_folder + '/text_to_process'\n",
    "with open(file_name, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "file_list = []\n",
    "file_list.append(file_name)\n",
    "# required for the tools\n",
    "non_text_labels = ['Table', 'Formula', 'Example', 'Definition']\n",
    "df_from_txt, non_text = process_regulations(file_list, cemad_reference_checker, non_text_labels)\n",
    "\n",
    "# Remove the file\n",
    "os.remove(file_name)\n",
    "# Remove the folder\n",
    "os.rmdir(tmp_folder)\n",
    "\n",
    "# now add in the sections_referenced\n",
    "df_from_txt['sections_referenced'] = \"\"\n",
    "for key, value in sections_referenced.items():\n",
    "    subset_df = df_from_txt[df_from_txt[\"section_reference\"]== key]\n",
    "    assert len(subset_df) > 0\n",
    "    df_from_txt.loc[subset_df.index, \"sections_referenced\"] = value\n",
    "\n",
    "assert existing_df.columns.to_list() == df_from_txt.columns.to_list()\n",
    "\n",
    "# Filter rows in df_from_txt where section_reference is not already in existing_df\n",
    "filtered_df = df_from_txt[~df_from_txt['section_reference'].isin(existing_df['section_reference'])]\n",
    "combined_df = pd.concat([existing_df, filtered_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_plus []\n",
      "|-- Z.1 [References]\n",
      "|   |-- (A) [Commodities]\n",
      "|   |   +-- (i) []\n",
      "|   |-- (B) [Travel]\n",
      "|   |   +-- (i) [Summary Travel Rules]\n",
      "|   |       |-- (a) []\n",
      "|   |       |-- (b) []\n",
      "|   |       |-- (c) []\n",
      "|   |       |-- (d) []\n",
      "|   |       |-- (e) []\n",
      "|   |       |-- (f) []\n",
      "|   |       |-- (g) []\n",
      "|   |       |-- (h) []\n",
      "|   |       |-- (i) []\n",
      "|   |       |-- (j) []\n",
      "|   |       +-- (k) []\n",
      "|   +-- (C) [Crypto Assets]\n",
      "|       +-- (i) []\n",
      "+-- Z.2 [Metadata]\n",
      "    +-- (A) [Version]\n",
      "        +-- (i) []\n"
     ]
    }
   ],
   "source": [
    "from file_tools.tree_tools import build_tree_for_regulation\n",
    "tree = build_tree_for_regulation(\"manual_plus\", combined_df, cemad_reference_checker)\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the updated dataframe over the old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#existing_document_csv\n",
    "existing_document_csv_1 = \"./inputs/documents/ad_manual_plus_1.csv\"\n",
    "combined_df.to_csv(existing_document_csv_1, encoding='utf-8', sep=\"|\", na_rep='', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the file ./inputs/index/ad_index_plus.parquet\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find the file ./inputs/index/ad_index_plus.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [105]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m index_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./inputs/index/ad_index_plus.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m existing_index_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_parquet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecryption_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\chat\\cemad\\env\\lib\\site-packages\\regulations_rag\\file_tools.py:19\u001b[0m, in \u001b[0;36mload_parquet_data\u001b[1;34m(path_to_file, decryption_key)\u001b[0m\n\u001b[0;32m     17\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[0;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(path_to_file, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decryption_key:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find the file ./inputs/index/ad_index_plus.parquet"
     ]
    }
   ],
   "source": [
    "index_file = \"./inputs/index/ad_index_plus.parquet\"\n",
    "existing_index_df = load_parquet_data(index_file, decryption_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regulations_rag.embeddings import get_ada_embedding\n",
    "from regulations_rag.embeddings import  EmbeddingParameters\n",
    "embedding_parameters = EmbeddingParameters(\"text-embedding-3-large\", 1024)\n",
    "\n",
    "list_to_add_to_index = []\n",
    "added_sections = filtered_df[\"section_reference\"].to_list()\n",
    "for row in index_for_new_text:\n",
    "    assert len(row) == 2\n",
    "    assert cemad_reference_checker.is_valid(row[0])\n",
    "    assert row[0] in added_sections\n",
    "    embedding = get_ada_embedding(openai_client, row[1], embedding_parameters.model, embedding_parameters.dimensions)  \n",
    "    list_to_add_to_index.append([row[0], row[1], \"document\", embedding, \"CEMAD_User_Queries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append_to_index = pd.DataFrame(list_to_add_to_index, columns = [\"section_reference\", \"text\", \"source\", \"embedding\", \"document\"])\n",
    "assert df_append_to_index.columns.to_list() == existing_index_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_index_df = pd.concat([existing_index_df, df_append_to_index], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parquet_data(combined_index_df, index_file, decryption_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
